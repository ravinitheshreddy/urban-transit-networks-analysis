{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f86f6ef-1d4b-4b05-bad6-5aa42d271158",
   "metadata": {},
   "source": [
    "# Graphs Creation\n",
    "\n",
    "In this notebook, the data about the transport networks are read from the CSV files and networkx graphs are created and stored. The data for each city is provided in a zip folder. Among many files, the files useful for us are `network_nodes.csv` and `network_combined.csv`. The former file contains information about the nodes (stops) such as the id, latitude, longitude and name. The latter file contains information about the edges (routes) such as the from the node to node, the straight line distance, the average duration between the stops, the number of times a public transport vehicle passes through that stop in an hour and the route type. The route type can be one of the following seven types: ` tram, subway, rail, bus, ferry, cablecar, gondola and funicular`. As there are different edges for different modes of transport the whole transport network graph is conceptualised as a MultiDiGraph. As the transport vehicles have a from and to node, it is represented in the graph as a directed graph. \n",
    "\n",
    "We found out that there are some self-loops in the edge data and we could not find the relevant information on the transportation website of the city. Hence we remove the edges with the same from and to id. \n",
    "\n",
    "We create a dictionary of graphs for each city with the mode of transport as the key and the network graph as the value. If a certain mode of transport does not exist, then the value is set to None. Apart from the individual modes, there will be one full graph as well. This dictionary of graphs is stored as a pickle file on the drive. Along with the dictionary of graphs, we store the `network_nodes.csv` and `network_combined.csv` for each city.\n",
    "\n",
    "We also make an undirected version of the graphs alongside the directed ones.\n",
    "\n",
    "Lastly, as none of the cities has gondola and funicular routes, that route type is excluded from the rest of the project.\n",
    "\n",
    "1. For each city, creates an empty dictionary to store graphs representing different types of transportation routes in the city.\n",
    "2. Extract the city name from the city zip file name, and read the node and edge data from CSV files in the zip file.\n",
    "3. Remove the self-loops from the edge data\n",
    "3. Create a MultiDiGraph for a full network of transportation routes in the city.\n",
    "4. Get the unique transportation route types in the edge data CSV file, and create a new DiGraph for each route type.\n",
    "5. Store the dictionary of graphs as a serialized pickle file with the name of the city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9d6c281-3fad-46df-9468-d851a57c0709",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "from zipfile import ZipFile\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd50bb09-a5c3-47fe-abd8-f363cbc508d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set paths for input data and output graphs\n",
    "rel_data_folder_path = pathlib.Path(\"./../../data\")\n",
    "transport_data_path = rel_data_folder_path.joinpath('transport_data')\n",
    "city_network_graphs = rel_data_folder_path.joinpath('network_graphs').joinpath('graphs')\n",
    "city_network_bones = rel_data_folder_path.joinpath('network_graphs').joinpath('nodes-edges')\n",
    "\n",
    "# Get list of zip files with transportation data\n",
    "city_zips = list(transport_data_path.glob('*.zip'))\n",
    "\n",
    "# Define enum for route types\n",
    "class RouteType(Enum):\n",
    "    tram, subway, rail, bus, ferry, cablecar = range(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8405ec1-f62f-4d77-a0d5-20be840e01e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loop over each zip folder for the city\n",
    "for city_data_path in city_zips:\n",
    "    \n",
    "    # Create dictionary to store graph representations of different route types and the full network\n",
    "    city_graphs_dir = {RouteType(idx).name: None for idx in range(len(RouteType))}\n",
    "    city_graphs_dir[\"full\"] = None\n",
    "    \n",
    "    # Create dictionary to store undirected graph representations of different route types and the full network\n",
    "    city_graphs_undir = {RouteType(idx).name: None for idx in range(len(RouteType))}\n",
    "    city_graphs_undir[\"full\"] = None\n",
    "    \n",
    "    # get the city name\n",
    "    city_zf = ZipFile(city_data_path)\n",
    "    city_name = city_data_path.name.removesuffix(\".zip\")\n",
    "        \n",
    "    # Read node information and save it to file\n",
    "    city_nodes_df = pd.read_csv(city_zf.open(city_name + '/network_nodes.csv'),sep=\";\")\n",
    "    city_zf.extract(city_name + '/network_nodes.csv', path=city_network_bones)\n",
    "    \n",
    "    # find the duplicate stops based on 'name' column\n",
    "    duplicate_stops = city_nodes_df[city_nodes_df.duplicated(subset=['name'], keep=False)]\n",
    "\n",
    "    # create the dictionary with key as the stop_I of duplicate row and value as the minimum among the stop_I of the duplicate rows\n",
    "    dup_stop_mapping = {}\n",
    "    for name, group in duplicate_stops.groupby('name'):\n",
    "        min_stop_I = group['stop_I'].min()\n",
    "        for stop_I in group['stop_I']:\n",
    "            if stop_I != min_stop_I:\n",
    "                dup_stop_mapping[stop_I] = min_stop_I\n",
    "\n",
    "    # drop the duplicate nodes\n",
    "    city_nodes_df.drop_duplicates(subset=['name'], keep='first', inplace=True)\n",
    "    \n",
    "    node_attrs = city_nodes_df.set_index('stop_I').to_dict('index')\n",
    "    \n",
    "    # read the edges information \n",
    "    city_network_df = pd.read_csv(city_zf.open(city_name + '/network_combined.csv'),sep=\";\")\n",
    "    \n",
    "    # replace the duplicate stop ids with the retained ones\n",
    "    city_network_df['from_stop_I'] = city_network_df['from_stop_I'].map(dup_stop_mapping).fillna(city_network_df['from_stop_I'])\n",
    "    city_network_df['to_stop_I'] = city_network_df['to_stop_I'].map(dup_stop_mapping).fillna(city_network_df['to_stop_I'])\n",
    "    \n",
    "    # remove self loops where the from stop and to stop are the same and save it to file\n",
    "    city_network_df = city_network_df.query(\"from_stop_I != to_stop_I\")\n",
    "    city_zf.extract(city_name + '/network_combined.csv', path=city_network_bones)\n",
    "\n",
    "     # Construct graph for full network\n",
    "    full_city_graph = nx.MultiDiGraph()\n",
    "\n",
    "    # Add edges to the graph\n",
    "    for _, row in city_network_df.iterrows():\n",
    "        source = row['from_stop_I']\n",
    "        target = row['to_stop_I']\n",
    "        edge_data = row[2:].to_dict()\n",
    "        full_city_graph.add_edge(source, target, **edge_data)\n",
    "\n",
    "    nx.set_node_attributes(full_city_graph, node_attrs)\n",
    "    \n",
    "    city_graphs_dir[\"full\"] = full_city_graph\n",
    "    city_graphs_undir[\"full\"] = full_city_graph.to_undirected()\n",
    "\n",
    "     # Construct graphs for different route types\n",
    "    rte_types = city_network_df[\"route_type\"].unique()\n",
    "\n",
    "    for rte_type in rte_types:\n",
    "        rte_network_df = city_network_df[city_network_df[\"route_type\"] == rte_type]\n",
    "\n",
    "        rte_type_graph = nx.DiGraph()\n",
    "\n",
    "        # Add edges to the graph\n",
    "        for _, row in rte_network_df.iterrows():\n",
    "            source = row['from_stop_I']\n",
    "            target = row['to_stop_I']\n",
    "            edge_data = row[2:].to_dict()\n",
    "            rte_type_graph.add_edge(source, target, **edge_data)\n",
    "\n",
    "        nx.set_node_attributes(rte_type_graph, node_attrs)\n",
    "        city_graphs_dir[RouteType(rte_type).name] = rte_type_graph\n",
    "        city_graphs_undir[RouteType(rte_type).name] = rte_type_graph.to_undirected()\n",
    "\n",
    "    # Save graphs for city to file\n",
    "    ## directed\n",
    "    city_network_graphs.joinpath('directed_graphs').mkdir(parents=True, exist_ok=True)\n",
    "    with open(city_network_graphs.joinpath('directed_graphs').joinpath(city_name + '.gpickle'), 'wb') as f:\n",
    "        pickle.dump(city_graphs_dir, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    ## undirected\n",
    "    city_network_graphs.joinpath('undirected_graphs').mkdir(parents=True, exist_ok=True)\n",
    "    with open(city_network_graphs.joinpath('undirected_graphs').joinpath(city_name + '.gpickle'), 'wb') as f:\n",
    "        pickle.dump(city_graphs_undir, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02ac2bf-d336-49e1-8c8a-008d89b57dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nml] *",
   "language": "python",
   "name": "conda-env-nml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
